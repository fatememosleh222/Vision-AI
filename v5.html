<!doctype html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Vision Assistant</title>
    <style>
        body {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
            height: 100%;
            font-family: 'Inter', 'Segoe UI', 'Roboto', sans-serif;
            background: linear-gradient(135deg, #0f0f23 0%, #1a1a2e 50%, #16213e 100%);
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: flex-start;
            text-align: center;
            color: white;
            overflow-x: hidden;
        }

        html {
            height: 100%;
        }

        .header-section {
            width: 100%;
            background: linear-gradient(135deg, rgba(0,123,255,0.1) 0%, rgba(102,126,234,0.1) 100%);
            border-bottom: 1px solid rgba(255,255,255,0.1);
            padding: 2rem 0;
            margin-bottom: 2rem;
        }

        .hackathon-badge {
            display: inline-block;
            background: linear-gradient(45deg, #00d4ff, #007bff);
            color: white;
            padding: 0.5rem 1.5rem;
            border-radius: 25px;
            font-size: 0.9rem;
            font-weight: 600;
            margin-bottom: 1rem;
            text-transform: uppercase;
            letter-spacing: 1px;
            box-shadow: 0 4px 15px rgba(0,123,255,0.3);
        }

        main {
            width: 90%;
            max-width: 1200px;
            padding: 0 2rem 2rem;
        }

        .app-title {
            font-size: 3.5rem;
            font-weight: 700;
            margin-bottom: 0.5rem;
            background: linear-gradient(135deg, #00d4ff 0%, #007bff 50%, #6c5ce7 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }

        .app-subtitle {
            font-size: 1.2rem;
            color: rgba(255,255,255,0.8);
            margin-bottom: 1rem;
            font-weight: 300;
        }

        .tech-stack {
            display: flex;
            justify-content: center;
            gap: 1rem;
            margin-bottom: 2rem;
            flex-wrap: wrap;
        }

        .tech-badge {
            background: rgba(255,255,255,0.1);
            border: 1px solid rgba(255,255,255,0.2);
            padding: 0.3rem 0.8rem;
            border-radius: 15px;
            font-size: 0.8rem;
            color: rgba(255,255,255,0.9);
        }

        .main-feature-panel {
            background: linear-gradient(135deg, rgba(0,212,255,0.1) 0%, rgba(0,123,255,0.1) 100%);
            border: 2px solid rgba(0,212,255,0.3);
            border-radius: 25px;
            padding: 2.5rem;
            margin-bottom: 3rem;
            text-align: center;
            box-shadow: 0 10px 40px rgba(0,123,255,0.2);
        }

        .feature-header h2 {
            color: #00d4ff;
            font-size: 2.2rem;
            margin-bottom: 0.5rem;
            font-weight: 700;
        }

        .feature-subtitle {
            font-size: 1.2rem;
            color: rgba(255,255,255,0.9);
            margin-bottom: 2rem;
        }

        .upload-button {
            background: linear-gradient(45deg, #00d4ff, #007bff);
            color: white;
            border: none;
            padding: 1.5rem 3rem;
            border-radius: 50px;
            font-size: 1.3rem;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 8px 25px rgba(0,123,255,0.4);
            text-transform: uppercase;
            letter-spacing: 1px;
        }

        .upload-button:hover {
            transform: translateY(-3px);
            box-shadow: 0 12px 35px rgba(0,123,255,0.6);
        }

        .analyze-button {
            background: linear-gradient(45deg, #28a745, #20c997);
            color: white;
            border: none;
            padding: 1.2rem 2.5rem;
            border-radius: 25px;
            font-size: 1.2rem;
            font-weight: 600;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 6px 20px rgba(40,167,69,0.4);
            margin-top: 1rem;
            text-transform: uppercase;
            letter-spacing: 1px;
        }

        .analyze-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 8px 25px rgba(40,167,69,0.6);
        }

        .photo-analysis-area {
            background: linear-gradient(135deg, rgba(40,167,69,0.15) 0%, rgba(32,201,151,0.15) 100%);
            border: 2px solid rgba(40,167,69,0.4);
            border-radius: 20px;
            padding: 2rem;
            margin-top: 2rem;
            backdrop-filter: blur(15px);
            box-shadow: 0 10px 30px rgba(40,167,69,0.3);
            min-height: 150px;
            display: none;
        }

        .photo-analysis-header {
            color: #28a745;
            font-size: 1.8rem;
            font-weight: 700;
            margin-bottom: 1rem;
            text-align: center;
            text-transform: uppercase;
            letter-spacing: 1px;
        }

        .photo-analysis-text {
            font-size: 1.1rem;
            line-height: 1.7;
            text-align: left;
            color: rgba(255,255,255,0.95);
            font-weight: 400;
            white-space: pre-wrap;
        }

        .upload-hint {
            color: rgba(255,255,255,0.7);
            font-size: 1rem;
            margin: 1rem 0 0 0;
        }

        @media (max-width: 768px) {
            .app-title {
                font-size: 2.5rem;
            }
        }
    </style>
</head>
<body>
    <div class="header-section">
        <div class="hackathon-badge">üèÜ Hackathon Project</div>
        <h1 class="app-title">VisionAI Assistant</h1>
        <p class="app-subtitle">Advanced Computer Vision &amp; Emotional AI Poetry</p>
        <div class="tech-stack">
            <span class="tech-badge">ü§ñ Vision Transformer</span>
            <span class="tech-badge">‚ú® GPT-2 Captioning</span>
            <span class="tech-badge">üé≠ FLAN-T5 Poetry</span>
            <span class="tech-badge">üîä Text-to-Speech</span>
            <span class="tech-badge">‚ö° Dual AI Pipeline</span>
        </div>
    </div>

    <main>
        <div class="main-feature-panel">
            <div class="feature-header">
                <h2>üì∏ Dual AI Image Analysis</h2>
                <p class="feature-subtitle">Upload any photo for Vision AI + Emotional Poetry Enhancement!</p>
            </div>
            
            <div class="image-upload-section">
                <input type="file" id="photo-upload" accept="image/*" style="display: none;">
                <button class="upload-button" id="browse-photo">üì∑ Choose Image to Analyze</button>
                <p class="upload-hint">Select any photo from your device</p>
                
                <div id="uploaded-photo-container" style="display: none; margin-top: 2rem;">
                    <img id="uploaded-photo" alt="Uploaded photo" style="max-width: 100%; max-height: 300px; border-radius: 15px; border: 2px solid rgba(0,212,255,0.3); box-shadow: 0 8px 25px rgba(0,0,0,0.3);">
                    <br>
                    <button class="analyze-button" id="analyze-photo">‚ú® Run Dual AI Analysis</button>
                </div>
            </div>

            <div class="photo-analysis-area" id="photo-analysis-area">
                <div class="photo-analysis-header">ü§ñ DUAL AI ANALYSIS RESULTS</div>
                <div class="photo-analysis-text" id="photo-analysis-text"></div>
            </div>
        </div>

        <div style="background: rgba(255,255,255,0.05); border-radius: 20px; padding: 2rem; backdrop-filter: blur(20px); border: 1px solid rgba(255,255,255,0.1);">
            <h3 style="color: #00d4ff; margin-bottom: 1rem;">üß† How It Works</h3>
            <div style="text-align: left; line-height: 1.8;">
                <p><strong>Step 1:</strong> üì∑ Vision Transformer + GPT-2 analyzes your image</p>
                <p><strong>Step 2:</strong> ‚ú® FLAN-T5-Large transforms the caption into emotional poetry</p>
                <p><strong>Result:</strong> üé≠ You get both factual understanding AND beautiful, moving descriptions!</p>
                <p style="margin-top: 1rem; color: rgba(255,193,7,0.9);"><em>‚è≥ First request may take 20-30 seconds as AI models load</em></p>
            </div>
        </div>
    </main>

    <script>
        const HF_TOKEN = 'personal_token';

        // Text-to-speech function
        function speak(text) {
            if ('speechSynthesis' in window) {
                const utterance = new SpeechSynthesisUtterance(text);
                utterance.rate = 0.9;
                utterance.pitch = 1;
                utterance.volume = 1;
                speechSynthesis.speak(utterance);
            }
        }

        // FIXED: Dual AI image analysis function
        async function analyzeUploadedPhoto(imageElement) {
            try {
                // STEP 1: Get basic caption from Vision AI
                const canvas = document.createElement('canvas');
                const ctx = canvas.getContext('2d');
                
                canvas.width = imageElement.naturalWidth;
                canvas.height = imageElement.naturalHeight;
                ctx.drawImage(imageElement, 0, 0);
                
                const base64Data = canvas.toDataURL('image/jpeg', 0.8).split(',')[1];
                const byteCharacters = atob(base64Data);
                const byteNumbers = new Array(byteCharacters.length);
                for (let i = 0; i < byteCharacters.length; i++) {
                    byteNumbers[i] = byteCharacters.charCodeAt(i);
                }
                const byteArray = new Uint8Array(byteNumbers);
                const blob = new Blob([byteArray], { type: 'image/jpeg' });
                
                console.log('Calling Vision API...');
                const visionResponse = await fetch('https://api-inference.huggingface.co/models/nlpconnect/vit-gpt2-image-captioning', {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${HF_TOKEN}`,
                        'Content-Type': 'application/octet-stream',
                    },
                    body: blob
                });
                
                if (!visionResponse.ok) {
                    throw new Error(`Vision API Error: ${visionResponse.status}`);
                }
                
                const visionResult = await visionResponse.json();
                console.log('Vision Result:', visionResult);
                
                let basicCaption = '';
                if (Array.isArray(visionResult) && visionResult.length > 0) {
                    basicCaption = visionResult[0].generated_text || visionResult[0].caption || 'No caption generated';
                } else if (visionResult.generated_text) {
                    basicCaption = visionResult.generated_text;
                } else if (visionResult.caption) {
                    basicCaption = visionResult.caption;
                } else {
                    basicCaption = 'Unable to generate caption';
                }
                
                // STEP 2: Enhance caption with emotional, poetic language
                console.log('Calling Poetry Enhancement API...');
                const emotionalPrompt = `Transform this simple image description into a beautiful, emotional, and poetic narrative. Make it vivid, heartfelt, and deeply moving while staying true to what's described:

"${basicCaption}"

Write a poetic, emotional description (2-3 sentences):`;

                const textResponse = await fetch('https://api-inference.huggingface.co/models/google/flan-t5-large', {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${HF_TOKEN}`,
                        'Content-Type': 'application/json',
                    },
                    body: JSON.stringify({ 
                        inputs: emotionalPrompt,
                        parameters: {
                            max_length: 200,
                            temperature: 0.9,
                            do_sample: true
                        }
                    })
                });
                
                let emotionalCaption = basicCaption;
                
                if (textResponse.ok) {
                    const textResult = await textResponse.json();
                    console.log('Poetry Result:', textResult);
                    
                    if (Array.isArray(textResult) && textResult.length > 0 && textResult[0].generated_text) {
                        emotionalCaption = textResult[0].generated_text;
                    } else if (textResult.generated_text) {
                        emotionalCaption = textResult.generated_text;
                    }
                } else {
                    console.log('Poetry enhancement unavailable, using basic caption');
                }
                
                // Format the response
                const formattedResponse = `ü§ñ DUAL AI VISION ANALYSIS

üîç STEP 1 - Vision AI (Basic Caption):
"${basicCaption}"

‚ú® STEP 2 - Emotional Enhancement (Poetry AI):
"${emotionalCaption}"

üìä AI PIPELINE:
‚Ä¢ Vision Transformer + GPT-2 ‚Üí Analyzed visual content
‚Ä¢ FLAN-T5-Large ‚Üí Enhanced with emotional depth

üß† DUAL MODEL APPROACH: First, a computer vision model understands what's in the image. Then, a language model transforms that understanding into poetic, emotional language that captures not just what is seen, but how it feels.

üí° TIP: This two-stage AI process creates descriptions that are both accurate and deeply moving!`;
                
                return formattedResponse;
                
            } catch (error) {
                console.error('AI Analysis Error:', error);
                
                const errorMessage = `‚ùå AI ANALYSIS ERROR

üîß TECHNICAL ISSUE: ${error.message}

üîÑ POSSIBLE SOLUTIONS:
‚Ä¢ AI models loading (first request: 20-30 seconds)
‚Ä¢ Check internet connection  
‚Ä¢ Hugging Face API temporarily unavailable
‚Ä¢ Try different image format (JPEG recommended)

ü§ñ DUAL AI SYSTEM:
1. Vision Transformer identifies image content
2. FLAN-T5 enhances with emotional poetry

üí° TIP: Wait a moment and try again - AI models need initialization time.`;
                
                return errorMessage;
            }
        }

        // Photo upload handler
        document.getElementById('browse-photo').addEventListener('click', function() {
            document.getElementById('photo-upload').click();
        });

        document.getElementById('photo-upload').addEventListener('change', function(event) {
            const file = event.target.files[0];
            if (file && file.type.startsWith('image/')) {
                const reader = new FileReader();
                reader.onload = function(e) {
                    const uploadedPhoto = document.getElementById('uploaded-photo');
                    const photoContainer = document.getElementById('uploaded-photo-container');
                    
                    uploadedPhoto.src = e.target.result;
                    photoContainer.style.display = 'block';
                    
                    speak("Photo uploaded successfully! Click the analyze button when ready.");
                };
                reader.readAsDataURL(file);
            }
        });

        // Analysis button handler
        document.getElementById('analyze-photo').addEventListener('click', async function() {
            const photoAnalysisArea = document.getElementById('photo-analysis-area');
            const photoAnalysisText = document.getElementById('photo-analysis-text');
            const analyzeButton = this;
            const uploadedPhoto = document.getElementById('uploaded-photo');
            
            // Disable button during processing
            analyzeButton.style.opacity = '0.6';
            analyzeButton.style.pointerEvents = 'none';
            analyzeButton.textContent = 'üîÑ Analyzing with Dual AI...';
            
            // Show processing state
            photoAnalysisText.textContent = '‚è≥ STEP 1: Sending image to Vision Transformer + GPT-2...\n\n(This may take 20-30 seconds on first use as the AI model loads)\n\nüß† The vision AI is analyzing visual features, objects, and scenes...';
            photoAnalysisArea.style.display = 'block';
            
            speak("Starting dual AI analysis. Please wait while the vision model processes your image.");
            
            try {
                // Call the AI analysis function
                const response = await analyzeUploadedPhoto(uploadedPhoto);
                photoAnalysisText.textContent = response;
                
                // Extract caption for speech
                const captionMatch = response.match(/STEP 1[^"]*"([^"]+)"/);
                const poetryMatch = response.match(/STEP 2[^"]*"([^"]+)"/);
                
                if (poetryMatch) {
                    speak(`AI analysis complete! ${poetryMatch[1]}`);
                } else if (captionMatch) {
                    speak(`AI analysis complete! The vision model sees: ${captionMatch[1]}`);
                } else {
                    speak("AI analysis complete! Check the results above.");
                }
                
            } catch (error) {
                console.error('Analysis failed:', error);
                photoAnalysisText.textContent = `‚ùå Analysis failed: ${error.message}`;
                speak("Sorry, the AI analysis encountered an error. Please try again.");
            } finally {
                // Re-enable button
                analyzeButton.style.opacity = '1';
                analyzeButton.style.pointerEvents = 'auto';
                analyzeButton.textContent = '‚ú® Run Dual AI Analysis Again';
            }
        });

        // Welcome message
        window.addEventListener('load', function() {
            setTimeout(() => {
                speak("Welcome to VisionAI Assistant with dual AI technology. Upload an image to experience vision analysis combined with emotional poetry enhancement.");
            }, 1000);
        });
    </script>
</body>
</html>